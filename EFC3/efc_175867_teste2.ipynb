{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../EFC3/bloodmnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainX = data[\"train_images\"]\n",
    "TrainY = data[\"train_labels\"]\n",
    "ValX = data[\"val_images\"]\n",
    "ValY = data[\"val_labels\"]\n",
    "TestX = data[\"test_images\"]\n",
    "TestY = data[\"test_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'dados de treinamento: \\n {len(TrainX[0])}')\n",
    "\n",
    "print('--'*20)\n",
    "print(f'\\n {TrainX/255}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainX_n = TrainX/255\n",
    "TestX_n = TestX/255\n",
    "ValX_n = ValX/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(10, kernel_size=(3,3),activation='relu',input_shape=(28,28,3)),   # Gera um feature-map de 26x26x20, uma vez que não estou considerando padding\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(8,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tam = [10, 12, 14, 16, 18, 20]\n",
    "ker = [3, 4, 5]\n",
    "best_accuracy = 0\n",
    "best_tam = None\n",
    "best_ker = None\n",
    "\n",
    "\n",
    "for i in tam:\n",
    "\n",
    "    for j in ker:\n",
    "\n",
    "        model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Conv2D(i, kernel_size=(j,j),activation='relu',input_shape=(28,28,3)),   # Gera um feature-map de 26x26x20, uma vez que não estou considerando padding\n",
    "                tf.keras.layers.MaxPooling2D((2,2)),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(8,activation='softmax')\n",
    "        ])\n",
    "        model.compile(optimizer='SGD',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "        \n",
    "        hist = model.fit(TrainX_n, TrainY, batch_size=8, epochs=30, verbose=1, validation_data=(ValX_n, ValY), callbacks=tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True))\n",
    "\n",
    "        val_acc = model.evaluate(ValX_n,ValY)\n",
    "\n",
    "        print(f'Qntde de Kernel {i} para o tamanho {j}: acc = {val_acc[1]} \\n')\n",
    "\n",
    "        if val_acc[1] > best_accuracy:\n",
    "            best_accuracy = val_acc\n",
    "            best_tam = i\n",
    "            best_ker = j\n",
    "\n",
    "print(f'A melhor quantidade e melhor tamanho é {best_tam}, {best_ker}, respectivamente')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(best_tam, kernel_size=(best_ker,best_ker),activation='relu',input_shape=(28,28,3)),   # Gera um feature-map de 26x26x20, uma vez que não estou considerando padding\n",
    "        tf.keras.layers.MaxPooling2D((2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(8,activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='SGD',\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy'])\n",
    "        \n",
    "hist = model.fit(TrainX_n, TrainY, batch_size=8, epochs=10, verbose=1, validation_data=(ValX_n, ValY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = hist.history['accuracy']\n",
    "validation_acc = hist.history['val_accuracy']\n",
    "\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "range_epochs = np.arange(10)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(range_epochs,acc, label='Acuracia Treinamento')\n",
    "plt.plot(range_epochs,validation_acc, label='Acuracia Validação')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range_epochs,loss, label='Função Custo Treinamento')\n",
    "plt.plot(range_epochs,val_loss, label='Função Custo Validação')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "#Plot the confusion matrix. Set Normalize = True/False\n",
    "def plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.around(cm, decimals=2)\n",
    "        cm[np.isnan(cm)] = 0.0\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "pred = model.predict(TestX_n)\n",
    "\n",
    "y_pred = np.empty((len(pred),1),dtype=int)\n",
    "for i in range(len(pred)):\n",
    "    y_pred[i,0] = np.argmax(pred[i])\n",
    "\n",
    "score = model.evaluate(TestX_n,TestY)\n",
    "\n",
    "print(f'Função-Custo: {score[0]}')\n",
    "print(f'Acurácia: {score[1]}')\n",
    "\n",
    "print('--'*50)\n",
    "\n",
    "cm = confusion_matrix(TestY,y_pred)\n",
    "plot_confusion_matrix(cm, ['0', '1', '2', '3', '4', '5', '6', '7'], normalize=False, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  true_label, img = true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(predicted_label,\n",
    "                                100*np.max(predictions_array),\n",
    "                                true_label),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  true_label = true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(8))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(8), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label[0]].set_color('blue')\n",
    "\n",
    "\n",
    "\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, pred[i], TestY, TestX)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, pred[i], TestY)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 14\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, pred[i], TestY, TestX)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, pred[i],  TestY)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
